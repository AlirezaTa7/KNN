//This Code is a Excercise for Data Scinese Lesson Called "KNN" This Code Will Work on Anaconda and Jupyter Notebooks.
//Import Libraries
//Import pandas,seaborn, and the usual libraries.
In[1]: import numpy as np
       import pandas as pd
       import matplotlib.pyplot as plt
       import seaborn as sns
       %matplotlib inline
   
  //Get the Data
  //Read the 'KNN_Project_Data csv file into a dataframe
In[2]: df = pd.read_csv('KNN_Project_Data')
In[3]: df.head()

//EDA
//Use seaborn on the dataframe to create a pairplot with the hue indicated by the TARGET CLASS column.
In[4]: sns.pairplot(df, hue = 'TARGET CLASS')
Out[4]: <seaborn.axisgrid.PairGrid at 0x10cde2c88>

//Train Test Split
//Use train_test_split to split your data into a training set and a testing set.
In [5]: from sklearn.model_selection import train_test_split
In [6]: y = df['TARGET CLASS']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)

//Using KNN
//Import KNeighborsClassifier from scikit learn.
In[7]: from sklearn.neighbors import KNeighborsClassifier
//Create a KNN model instance with n_neighbors=1
In[8]: myKNN = KNeighborsClassifier(n_neighbors = 1)
//Fit this KNN model to the training data.
In[9]: myKNN.fit(X_train, y_train)
Out[9]: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=1, p=2,
           weights='uniform')
        
 //Predictions and Evaluations
 
//Use the predict method to predict values using your KNN model and X_test.
In[10]: y_predict = myKNN.predict(X_test)
In [11]: from sklearn.metrics import confusion_matrix, classification_report
In[12]: print(confusion_matrix(y_test,y_predict))
[[109  43]
 [ 41 107]]
 In[13]: print(classification_report(y_test,y_predict))
  precision    recall  f1-score   support

          0       0.73      0.72      0.72       152
          1       0.71      0.72      0.72       148

avg / total       0.72      0.72      0.72       300


